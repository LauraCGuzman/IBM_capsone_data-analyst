{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "prev_pub_hash": "fee3cd0da99af27f7f7a8d9c340e8e78f253ffc32a2251cadcb6968f21d952d5"
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "<p style=\"text-align:center\">\n    <a href=\"https://skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDA0321ENSkillsNetwork928-2022-01-01\" target=\"_blank\">\n    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"400\" alt=\"Skills Network Logo\"  />\n    </a>\n</p>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# **Data Wrangling Lab**\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Estimated time needed: **45 to 60** minutes\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "In this assignment you will be performing data wrangling.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Objectives\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "In this lab you will perform the following:\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "-   Identify duplicate values in the dataset.\n\n-   Remove duplicate values from the dataset.\n\n-   Identify missing values in the dataset.\n\n-   Impute the missing values in the dataset.\n\n-   Normalize data in the dataset.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<hr>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Hands on Lab\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Import pandas module.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "<ipython-input-1-7dd3504c366f>:1: DeprecationWarning: \nPyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\nbut was not found to be installed on your system.\nIf this would cause problems for you,\nplease provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n        \n  import pandas as pd\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": "Load the dataset into a dataframe.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<h2>Read Data</h2>\n<p>\nWe utilize the <code>pandas.read_csv()</code> function for reading CSV files. However, in this version of the lab, which operates on JupyterLite, the dataset needs to be downloaded to the interface using the provided code below.\n</p>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "The functions below will download the dataset into your browser:\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from pyodide.http import pyfetch\n\nasync def download(url, filename):\n    response = await pyfetch(url)\n    if response.status == 200:\n        with open(filename, \"wb\") as f:\n            f.write(await response.bytes())",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": "file_path = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/LargeData/m1_survey_data.csv\"",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "source": "To obtain the dataset, utilize the download() function as defined above:  \n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "await download(file_path, \"m1_survey_data.csv\")\nfile_name=\"m1_survey_data.csv\"",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "source": "Utilize the Pandas method read_csv() to load the data into a dataframe.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df = pd.read_csv(file_name)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 25
    },
    {
      "cell_type": "markdown",
      "source": "> Note: This version of the lab is working on JupyterLite, which requires the dataset to be downloaded to the interface.While working on the downloaded version of this notebook on their local machines(Jupyter Anaconda), the learners can simply **skip the steps above,** and simply use the URL directly in the `pandas.read_csv()` function. You can uncomment and run the statements in the cell below.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#df = pd.read_csv(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/LargeData/m1_survey_data.csv\")",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Finding duplicates\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "In this section you will identify duplicate values in the dataset.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": " Find how many duplicate rows exist in the dataframe.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# your code goes here\ndf_duplicated = df.duplicated()\ndf_duplicated.sum()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 26,
          "output_type": "execute_result",
          "data": {
            "text/plain": "154"
          },
          "metadata": {}
        }
      ],
      "execution_count": 26
    },
    {
      "cell_type": "code",
      "source": "df[\"Respondent\"].duplicated().sum()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 27,
          "output_type": "execute_result",
          "data": {
            "text/plain": "154"
          },
          "metadata": {}
        }
      ],
      "execution_count": 27
    },
    {
      "cell_type": "markdown",
      "source": "## Removing duplicates\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Remove the duplicate rows from the dataframe.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# your code goes here\ndf_without_duplicates  = df.drop_duplicates()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 28
    },
    {
      "cell_type": "markdown",
      "source": "Verify if duplicates were actually dropped.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# your code goes here\ndf_without_duplicates.duplicated().sum()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 29,
          "output_type": "execute_result",
          "data": {
            "text/plain": "0"
          },
          "metadata": {}
        }
      ],
      "execution_count": 29
    },
    {
      "cell_type": "code",
      "source": "df_without_duplicates.info()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "<class 'pandas.core.frame.DataFrame'>\nIndex: 11398 entries, 0 to 11551\nData columns (total 85 columns):\n #   Column                  Non-Null Count  Dtype  \n---  ------                  --------------  -----  \n 0   Respondent              11398 non-null  int64  \n 1   MainBranch              11398 non-null  object \n 2   Hobbyist                11398 non-null  object \n 3   OpenSourcer             11398 non-null  object \n 4   OpenSource              11317 non-null  object \n 5   Employment              11398 non-null  object \n 6   Country                 11398 non-null  object \n 7   Student                 11347 non-null  object \n 8   EdLevel                 11286 non-null  object \n 9   UndergradMajor          10661 non-null  object \n 10  EduOther                11234 non-null  object \n 11  OrgSize                 11302 non-null  object \n 12  DevType                 11333 non-null  object \n 13  YearsCode               11389 non-null  object \n 14  Age1stCode              11385 non-null  object \n 15  YearsCodePro            11382 non-null  object \n 16  CareerSat               11398 non-null  object \n 17  JobSat                  11397 non-null  object \n 18  MgrIdiot                10905 non-null  object \n 19  MgrMoney                10901 non-null  object \n 20  MgrWant                 10905 non-null  object \n 21  JobSeek                 11398 non-null  object \n 22  LastHireDate            11398 non-null  object \n 23  LastInt                 10985 non-null  object \n 24  FizzBuzz                11361 non-null  object \n 25  JobFactors              11395 non-null  object \n 26  ResumeUpdate            11359 non-null  object \n 27  CurrencySymbol          11398 non-null  object \n 28  CurrencyDesc            11398 non-null  object \n 29  CompTotal               10589 non-null  float64\n 30  CompFreq                11192 non-null  object \n 31  ConvertedComp           10582 non-null  float64\n 32  WorkWeekHrs             11276 non-null  float64\n 33  WorkPlan                11277 non-null  object \n 34  WorkChallenge           11234 non-null  object \n 35  WorkRemote              11390 non-null  object \n 36  WorkLoc                 11366 non-null  object \n 37  ImpSyn                  11393 non-null  object \n 38  CodeRev                 11397 non-null  object \n 39  CodeRevHrs              8972 non-null   float64\n 40  UnitTests               11369 non-null  object \n 41  PurchaseHow             11202 non-null  object \n 42  PurchaseWhat            11360 non-null  object \n 43  LanguageWorkedWith      11387 non-null  object \n 44  LanguageDesireNextYear  11264 non-null  object \n 45  DatabaseWorkedWith      10945 non-null  object \n 46  DatabaseDesireNextYear  10356 non-null  object \n 47  PlatformWorkedWith      10987 non-null  object \n 48  PlatformDesireNextYear  10854 non-null  object \n 49  WebFrameWorkedWith      10005 non-null  object \n 50  WebFrameDesireNextYear  9781 non-null   object \n 51  MiscTechWorkedWith      9216 non-null   object \n 52  MiscTechDesireNextYear  9943 non-null   object \n 53  DevEnviron              11369 non-null  object \n 54  OpSys                   11364 non-null  object \n 55  Containers              11316 non-null  object \n 56  BlockchainOrg           9076 non-null   object \n 57  BlockchainIs            8788 non-null   object \n 58  BetterLife              11300 non-null  object \n 59  ITperson                11363 non-null  object \n 60  OffOn                   11360 non-null  object \n 61  SocialMedia             11105 non-null  object \n 62  Extraversion            11378 non-null  object \n 63  ScreenName              10891 non-null  object \n 64  SOVisit1st              11073 non-null  object \n 65  SOVisitFreq             11393 non-null  object \n 66  SOVisitTo               11397 non-null  object \n 67  SOFindAnswer            11395 non-null  object \n 68  SOTimeSaved             11348 non-null  object \n 69  SOHowMuchTime           9481 non-null   object \n 70  SOAccount               11397 non-null  object \n 71  SOPartFreq              10270 non-null  object \n 72  SOJobs                  11392 non-null  object \n 73  EntTeams                11393 non-null  object \n 74  SOComm                  11398 non-null  object \n 75  WelcomeChange           11313 non-null  object \n 76  SONewContent            9433 non-null   object \n 77  Age                     11111 non-null  float64\n 78  Gender                  11325 non-null  object \n 79  Trans                   11275 non-null  object \n 80  Sexuality               10856 non-null  object \n 81  Ethnicity               10723 non-null  object \n 82  Dependents              11258 non-null  object \n 83  SurveyLength            11379 non-null  object \n 84  SurveyEase              11384 non-null  object \ndtypes: float64(5), int64(1), object(79)\nmemory usage: 4.0+ MB\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 30
    },
    {
      "cell_type": "code",
      "source": "df_without_duplicates[\"Respondent\"].unique()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 31,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([    4,     9,    13, ..., 25138, 25141, 25142], dtype=int64)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 31
    },
    {
      "cell_type": "markdown",
      "source": "## Finding Missing values\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Find the missing values for all columns.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# your code goes here\ntotal_length = len(df_without_duplicates)\n\n# Iterar sobre cada columna y contar valores no nulos\nfor columna in df_without_duplicates.columns:\n    column_length_no_null = df_without_duplicates[columna].count()\n    empty_values = total_length - column_length_no_null\n    if empty_values > 0:\n        print(f\"Column '{columna}' has {empty_values} empty values.\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Column 'OpenSource' has 81 empty values.\nColumn 'Student' has 51 empty values.\nColumn 'EdLevel' has 112 empty values.\nColumn 'UndergradMajor' has 737 empty values.\nColumn 'EduOther' has 164 empty values.\nColumn 'OrgSize' has 96 empty values.\nColumn 'DevType' has 65 empty values.\nColumn 'YearsCode' has 9 empty values.\nColumn 'Age1stCode' has 13 empty values.\nColumn 'YearsCodePro' has 16 empty values.\nColumn 'JobSat' has 1 empty values.\nColumn 'MgrIdiot' has 493 empty values.\nColumn 'MgrMoney' has 497 empty values.\nColumn 'MgrWant' has 493 empty values.\nColumn 'LastInt' has 413 empty values.\nColumn 'FizzBuzz' has 37 empty values.\nColumn 'JobFactors' has 3 empty values.\nColumn 'ResumeUpdate' has 39 empty values.\nColumn 'CompTotal' has 809 empty values.\nColumn 'CompFreq' has 206 empty values.\nColumn 'ConvertedComp' has 816 empty values.\nColumn 'WorkWeekHrs' has 122 empty values.\nColumn 'WorkPlan' has 121 empty values.\nColumn 'WorkChallenge' has 164 empty values.\nColumn 'WorkRemote' has 8 empty values.\nColumn 'WorkLoc' has 32 empty values.\nColumn 'ImpSyn' has 5 empty values.\nColumn 'CodeRev' has 1 empty values.\nColumn 'CodeRevHrs' has 2426 empty values.\nColumn 'UnitTests' has 29 empty values.\nColumn 'PurchaseHow' has 196 empty values.\nColumn 'PurchaseWhat' has 38 empty values.\nColumn 'LanguageWorkedWith' has 11 empty values.\nColumn 'LanguageDesireNextYear' has 134 empty values.\nColumn 'DatabaseWorkedWith' has 453 empty values.\nColumn 'DatabaseDesireNextYear' has 1042 empty values.\nColumn 'PlatformWorkedWith' has 411 empty values.\nColumn 'PlatformDesireNextYear' has 544 empty values.\nColumn 'WebFrameWorkedWith' has 1393 empty values.\nColumn 'WebFrameDesireNextYear' has 1617 empty values.\nColumn 'MiscTechWorkedWith' has 2182 empty values.\nColumn 'MiscTechDesireNextYear' has 1455 empty values.\nColumn 'DevEnviron' has 29 empty values.\nColumn 'OpSys' has 34 empty values.\nColumn 'Containers' has 82 empty values.\nColumn 'BlockchainOrg' has 2322 empty values.\nColumn 'BlockchainIs' has 2610 empty values.\nColumn 'BetterLife' has 98 empty values.\nColumn 'ITperson' has 35 empty values.\nColumn 'OffOn' has 38 empty values.\nColumn 'SocialMedia' has 293 empty values.\nColumn 'Extraversion' has 20 empty values.\nColumn 'ScreenName' has 507 empty values.\nColumn 'SOVisit1st' has 325 empty values.\nColumn 'SOVisitFreq' has 5 empty values.\nColumn 'SOVisitTo' has 1 empty values.\nColumn 'SOFindAnswer' has 3 empty values.\nColumn 'SOTimeSaved' has 50 empty values.\nColumn 'SOHowMuchTime' has 1917 empty values.\nColumn 'SOAccount' has 1 empty values.\nColumn 'SOPartFreq' has 1128 empty values.\nColumn 'SOJobs' has 6 empty values.\nColumn 'EntTeams' has 5 empty values.\nColumn 'WelcomeChange' has 85 empty values.\nColumn 'SONewContent' has 1965 empty values.\nColumn 'Age' has 287 empty values.\nColumn 'Gender' has 73 empty values.\nColumn 'Trans' has 123 empty values.\nColumn 'Sexuality' has 542 empty values.\nColumn 'Ethnicity' has 675 empty values.\nColumn 'Dependents' has 140 empty values.\nColumn 'SurveyLength' has 19 empty values.\nColumn 'SurveyEase' has 14 empty values.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 32
    },
    {
      "cell_type": "markdown",
      "source": "Find out how many rows are missing in the column 'WorkLoc'\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# your code goes here\nlen(df_without_duplicates)-df_without_duplicates[\"WorkLoc\"].count()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 33,
          "output_type": "execute_result",
          "data": {
            "text/plain": "32"
          },
          "metadata": {}
        }
      ],
      "execution_count": 33
    },
    {
      "cell_type": "markdown",
      "source": "## Imputing missing values\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Find the  value counts for the column WorkLoc.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# your code goes here\ndf_without_duplicates[\"WorkLoc\"].count()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 34,
          "output_type": "execute_result",
          "data": {
            "text/plain": "11366"
          },
          "metadata": {}
        }
      ],
      "execution_count": 34
    },
    {
      "cell_type": "markdown",
      "source": "Identify the value that is most frequent (majority) in the WorkLoc column.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#make a note of the majority value here, for future reference\n# Office\ndf_without_duplicates[\"Employment\"].mode()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 36,
          "output_type": "execute_result",
          "data": {
            "text/plain": "0    Employed full-time\nName: Employment, dtype: object"
          },
          "metadata": {}
        }
      ],
      "execution_count": 36
    },
    {
      "cell_type": "code",
      "source": "df_without_duplicates[\"WorkLoc\"].mode()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 37,
          "output_type": "execute_result",
          "data": {
            "text/plain": "0    Office\nName: WorkLoc, dtype: object"
          },
          "metadata": {}
        }
      ],
      "execution_count": 37
    },
    {
      "cell_type": "code",
      "source": "df_without_duplicates[\"UndergradMajor\"].value_counts().idxmin()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 40,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'A health science (ex. nursing, pharmacy, radiology)'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 40
    },
    {
      "cell_type": "markdown",
      "source": "Impute (replace) all the empty rows in the column WorkLoc with the value that you have identified as majority.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# your code goes here\ndf_without_duplicates['WorkLoc'] = df_without_duplicates['WorkLoc'].fillna('Office')",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "<ipython-input-41-a4ebedbcfe74>:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_without_duplicates['WorkLoc'] = df_without_duplicates['WorkLoc'].fillna('Office')\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 41
    },
    {
      "cell_type": "markdown",
      "source": "After imputation there should ideally not be any empty rows in the WorkLoc column.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Verify if imputing was successful.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# your code goes here\nlen(df_without_duplicates)-df_without_duplicates[\"WorkLoc\"].count()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 42,
          "output_type": "execute_result",
          "data": {
            "text/plain": "0"
          },
          "metadata": {}
        }
      ],
      "execution_count": 42
    },
    {
      "cell_type": "markdown",
      "source": "## Normalizing data\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "There are two columns in the dataset that talk about compensation.\n\nOne is \"CompFreq\". This column shows how often a developer is paid (Yearly, Monthly, Weekly).\n\nThe other is \"CompTotal\". This column talks about how much the developer is paid per Year, Month, or Week depending upon his/her \"CompFreq\". \n\nThis makes it difficult to compare the total compensation of the developers.\n\nIn this section you will create a new column called 'NormalizedAnnualCompensation' which contains the 'Annual Compensation' irrespective of the 'CompFreq'.\n\nOnce this column is ready, it makes comparison of salaries easy.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<hr>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "List out the various categories in the column 'CompFreq'\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# your code goes here\ndf_without_duplicates[\"CompFreq\"].unique()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 43,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array(['Yearly', 'Monthly', 'Weekly', nan], dtype=object)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 43
    },
    {
      "cell_type": "markdown",
      "source": "Create a new column named 'NormalizedAnnualCompensation'. Use the hint given below if needed.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Double click to see the **Hint**.\n\n<!--\n\nUse the below logic to arrive at the values for the column NormalizedAnnualCompensation.\n\nIf the CompFreq is Yearly then use the exising value in CompTotal\nIf the CompFreq is Monthly then multiply the value in CompTotal with 12 (months in an year)\nIf the CompFreq is Weekly then multiply the value in CompTotal with 52 (weeks in an year)\n\n-->\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# your code goes here\ndf_without_duplicates['NormalizedAnnualCompensation'] = df_without_duplicates['CompTotal']\ndf_without_duplicates.loc[df_without_duplicates['CompFreq'] == 'Monthly', 'NormalizedAnnualCompensation'] *= 12\ndf_without_duplicates.loc[df_without_duplicates['CompFreq'] == 'Weekly', 'NormalizedAnnualCompensation'] *= 52",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "<ipython-input-46-27735a2701f8>:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_without_duplicates['NormalizedAnnualCompensation'] = df_without_duplicates['CompTotal']\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 46
    },
    {
      "cell_type": "code",
      "source": "df_without_duplicates[\"CompFreq\"].loc[df_without_duplicates['CompFreq'] == 'Yearly'].count()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 48,
          "output_type": "execute_result",
          "data": {
            "text/plain": "6073"
          },
          "metadata": {}
        }
      ],
      "execution_count": 48
    },
    {
      "cell_type": "code",
      "source": "df_without_duplicates[\"NormalizedAnnualCompensation\"].median()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 49,
          "output_type": "execute_result",
          "data": {
            "text/plain": "100000.0"
          },
          "metadata": {}
        }
      ],
      "execution_count": 49
    },
    {
      "cell_type": "markdown",
      "source": "## Authors\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Ramesh Sannareddy\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Other Contributors\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Rav Ahuja\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": " ## Change Log\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "|Date (YYYY-MM-DD)|Version|Changed By|Change Description|\n|-|-|-|-|\n|2024-09-24|1.1|Madhusudhan Moole|Updated lab|\n|2024-09-23|1.0|Raghul Ramesh|Created lab|\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<!--| Date (YYYY-MM-DD) | Version | Changed By        | Change Description                 |\n| ----------------- | ------- | ----------------- | ---------------------------------- |\n| 2020-10-17        | 0.1     | Ramesh Sannareddy | Created initial version of the lab |--!>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## <h3 align=\"center\"> Â© IBM Corporation. All rights reserved. <h3/>\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    }
  ]
}